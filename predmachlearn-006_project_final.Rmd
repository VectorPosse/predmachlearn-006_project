---
title: "Course Project"
subtitle: "(predmachlearn-006)"
output: html_document
---

## Introduction

Data was collected from accelerometers on the belt, forearm, arm, and dumbbell of six participants who were asked to perform barbell lifts correctly and incorrectly in 5 different ways.<sup><a href="#fn1" id="ref1">1</a></sup> The goal of this project is to use training data to try to predict which method of lifting was used given the values derived from the accelerometer measurements. Then, the training model will be applied to a test set of 20 additional measurements.

## Preliminaries

First, we load the `dplyr` library for data frame manipulation, `ggplot2` for graphing, and `caret` for machine learning.

```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(caret)
```

## Importing and cleaning data

Now we import the training data and the testing data.

```{r, cache=TRUE}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

We need to clean the data. The only variables we'll be able to use are those variables with data in the testing set. The `classe` variable is the outcome, with `A` being the correct lifting technique, and `B` through `E` various incorrect techniques.

```{r}
# Get rid of irrelevant variables and convert everything to numeric.
testing2 <- testing %>%
    select(-c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2,
              cvtd_timestamp, new_window, num_window)) %>%
    mutate_each(funs(suppressWarnings(as.numeric(as.character(.)))))
# Find variables that are full of nothing but NAs and subset then out.
empty <- sapply(testing2, function(x) { 
    ifelse(mean(is.na(x)) == 1, TRUE, FALSE)
        })
testing2 <- testing2[,!empty]; rm(empty)
# Subset training data using the same variables
training2 <- training[, colnames(training) %in% colnames(testing2)]
training2 <- cbind(training2, classe = training$classe)
# Clean up workspace
rm(testing)
rm(training)
```

## Model fitting

Now we fit a model using boosting with cross-validation.

```{r, cache=TRUE, message=FALSE}
fitControl <- trainControl(method = "repeatedcv",
                           p = 0.75)
model <- train(classe ~ .,
               data = training2,
               method = "gbm",
               trControl = fitControl,
               verbose = FALSE)
```

We check in-sample accuracy with a confusion matrix.

```{r, message=FALSE}
pred_in <- predict(model, newdata = training2)
conf <- confusionMatrix(pred_in, training2$classe)
print(conf)
```

The in-sample accuracy is `r 100 * round(conf$overall[1], 3)`%.

We can assess the performance of the model:

```{r}
model$results
ggplot(model)
```

Through cross-validation, we can see that the expected out-of-sample accuracy&mdash;with max tree depth 3 and 150 boosting iterations&mdash;could be over 95%.

## Test predictions

Here are the model predictions on the test set:

```{r}
pred_out <- predict(model, newdata = testing2)
ans <- data.frame(pred_out = pred_out)
ans
```

____________________

<sup id="fn1">1. Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.<a href="#ref1" title="Jump back to footnote 1 in the text.">â†©</a></sup>